{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Parameters and Tensor Sizes in a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function\n",
    "\n",
    "def summary(model, input_size, batch_size=-1, device=\"cuda\"):\n",
    "\n",
    "    def register_hook(module):\n",
    "\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "            summary[m_key][\"input_shape\"][0] = batch_size\n",
    "            if isinstance(output, (list, tuple)):\n",
    "                summary[m_key][\"output_shape\"] = [\n",
    "                    [-1] + list(o.size())[1:] for o in output\n",
    "                ]\n",
    "            else:\n",
    "                summary[m_key][\"output_shape\"] = list(output.size())\n",
    "                summary[m_key][\"output_shape\"][0] = batch_size\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key][\"nb_params\"] = params\n",
    "\n",
    "        if (\n",
    "            not isinstance(module, nn.Sequential)\n",
    "            and not isinstance(module, nn.ModuleList)\n",
    "            and not (module == model)\n",
    "        ):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    device = device.lower()\n",
    "    assert device in [\n",
    "        \"cuda\",\n",
    "        \"cpu\",\n",
    "    ], \"Input device is not valid, please specify 'cuda' or 'cpu'\"\n",
    "\n",
    "    if device == \"cuda\" and torch.cuda.is_available():\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    # multiple inputs to the network\n",
    "    if isinstance(input_size, tuple):\n",
    "        input_size = [input_size]\n",
    "\n",
    "    # batch_size of 2 for batchnorm\n",
    "    x = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]\n",
    "    # print(type(x[0]))\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "\n",
    "    # make a forward pass\n",
    "    # print(x.shape)\n",
    "    model(*x)\n",
    "\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer (type)\", \"Output Shape\", \"Param #\")\n",
    "    print(line_new)\n",
    "    print(\"================================================================\")\n",
    "    total_params = 0\n",
    "    total_output = 0\n",
    "    trainable_params = 0\n",
    "    for layer in summary:\n",
    "        # input_shape, output_shape, trainable, nb_params\n",
    "        line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "            layer,\n",
    "            str(summary[layer][\"output_shape\"]),\n",
    "            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "        )\n",
    "        total_params += summary[layer][\"nb_params\"]\n",
    "        total_output += np.prod(summary[layer][\"output_shape\"])\n",
    "        if \"trainable\" in summary[layer]:\n",
    "            if summary[layer][\"trainable\"] == True:\n",
    "                trainable_params += summary[layer][\"nb_params\"]\n",
    "        print(line_new)\n",
    "\n",
    "    # assume 4 bytes/number (float on cuda).\n",
    "    total_input_size = abs(np.prod(input_size) * batch_size * 4. / (1024 ** 2.))\n",
    "    total_output_size = abs(2. * total_output * 4. / (1024 ** 2.))  # x2 for gradients\n",
    "    total_params_size = abs(total_params.numpy() * 4. / (1024 ** 2.))\n",
    "    total_size = total_params_size + total_output_size + total_input_size\n",
    "\n",
    "    print(\"================================================================\")\n",
    "    print(\"Total params: {0:,}\".format(total_params))\n",
    "    print(\"Trainable params: {0:,}\".format(trainable_params))\n",
    "    print(\"Non-trainable params: {0:,}\".format(total_params - trainable_params))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Input size (MB): %0.2f\" % total_input_size)\n",
    "    print(\"Forward/backward pass size (MB): %0.2f\" % total_output_size)\n",
    "    print(\"Params size (MB): %0.2f\" % total_params_size)\n",
    "    print(\"Estimated Total Size (MB): %0.2f\" % total_size)\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    # return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining the Convolutional Neural Network\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.conv1 = nn.Conv2d(3, 20, 5, 1) # channel = 3, no of filters = 20, kernel size = 5, stride =1, padding = 0\n",
    "      self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "      self.fc1 = nn.Linear(4*4*50, 500)\n",
    "      self.dropout1 = nn.Dropout(0.5)\n",
    "      self.fc2 = nn.Linear(500, 10)\n",
    "    def forward(self, x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = F.max_pool2d(x, 2, 2)\n",
    "      x = F.relu(self.conv2(x))\n",
    "      x = F.max_pool2d(x, 2, 2)\n",
    "      x = x.view(-1, 4*4*50)\n",
    "      x = F.relu(self.fc1(x))\n",
    "      x = self.dropout1(x)\n",
    "      x = self.fc2(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 20, 24, 24]           1,520\n",
      "            Conv2d-2             [-1, 50, 8, 8]          25,050\n",
      "            Linear-3                  [-1, 500]         400,500\n",
      "           Dropout-4                  [-1, 500]               0\n",
      "            Linear-5                   [-1, 10]           5,010\n",
      "================================================================\n",
      "Total params: 432,080\n",
      "Trainable params: 432,080\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 1.65\n",
      "Estimated Total Size (MB): 1.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = LeNet().to(device)\n",
    "\n",
    "summary(model, (3, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size of the Output Tensor (Image) of a Conv Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s define\n",
    "\n",
    "O = Size (width) of output image.\n",
    "\n",
    "I = Size (width) of input image.\n",
    "\n",
    "K = Size (width) of kernels used in the Conv Layer.\n",
    "\n",
    "N = Number of kernels.\n",
    "\n",
    "S = Stride of the convolution operation.\n",
    "\n",
    "P = Padding.\n",
    "\n",
    "The size (O) of the output image is given by\n",
    "\n",
    "    O = [(I - K + 2P)/ S] + 1 \n",
    "\n",
    "The number of channels in the output image is equal to the number of kernels N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size of Output Tensor (Image) of a MaxPool Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s define\n",
    "\n",
    "O = Size (width) of output image.\n",
    "\n",
    "I = Size (width) of input image.\n",
    "\n",
    "S = Stride of the convolution operation.\n",
    "\n",
    "P_s = Pool size.\n",
    "\n",
    "The size (O) of the output image is given by\n",
    "\n",
    "\n",
    "O = [(I - P_s) / S] + 1\n",
    "\n",
    "Note that this can be obtained using the formula for the convolution layer by making padding equal to zero and keeping P_s same as the kernel size. But unlike the convolution layer, the number of channels in the maxpool layer’s output is unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size of the output of a Fully Connected Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fully connected layer outputs a vector of length equal to the number of neurons in the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Parameters of a Conv Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a CNN, each layer has two kinds of parameters : weights and biases. The total number of parameters is just the sum of all weights and biases.\n",
    "\n",
    "Let’s define,\n",
    "\n",
    "W_c = Number of weights of the Conv Layer.\n",
    "\n",
    "B_c = Number of biases of the Conv Layer.\n",
    "\n",
    "P_c = Number of parameters of the Conv Layer.\n",
    "\n",
    "K = Size (width) of kernels used in the Conv Layer.\n",
    "\n",
    "N = Number of kernels.\n",
    "\n",
    "C = Number of channels of the input image.\n",
    "\n",
    "    W_c = K^2 * C * N\n",
    "    \n",
    "    B_c = N\n",
    "    \n",
    "    P_c = W_c + B_c\n",
    "\n",
    "In a Conv Layer, the depth of every kernel is always equal to the number of channels in the input image. So every kernel has K^2 * C parameters, and there are N such kernels. That’s how we come up with the above formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Parameters of a MaxPool Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no parameters associated with a MaxPool layer. The pool size, stride, and padding are hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Parameters of a Fully Connected (FC) Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two kinds of fully connected layers in a CNN. The first FC layer is connected to the last Conv Layer, while later FC layers are connected to other FC layers. Let’s consider each case separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1: Number of Parameters of a Fully Connected (FC) Layer connected to a Conv Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s define,\n",
    "\n",
    "W_{cf} = Number of weights of a FC Layer which is connected to a Conv Layer.\n",
    "\n",
    "B_{cf} = Number of biases of a FC Layer which is connected to a Conv Layer.\n",
    "\n",
    "O = Size (width) of the output image of the previous Conv Layer.\n",
    "\n",
    "N = Number of kernels in the previous Conv Layer.\n",
    "\n",
    "F = Number of neurons in the FC Layer.\n",
    "\n",
    "\n",
    "W_{cf} = O^2 * N * F\n",
    "\n",
    "B_{cf} = F\n",
    "\n",
    "P_{cf} = W_{cf} + B_{cf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2: Number of Parameters of a Fully Connected (FC) Layer connected to a FC Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s define,\n",
    "\n",
    "W_{ff} = Number of weights of a FC Layer which is connected to an FC Layer.\n",
    "\n",
    "B_{ff} = Number of biases of a FC Layer which is connected to an FC Layer.\n",
    "\n",
    "P_{ff} = Number of parameters of a FC Layer which is connected to an FC Layer.\n",
    "\n",
    "F = Number of neurons in the FC Layer.\n",
    "\n",
    "F_{-1} = Number of neurons in the previous FC Layer.\n",
    "\n",
    "\n",
    "W_{ff} = F_{-1} * F\n",
    "\n",
    "B_{ff} = F\n",
    "\n",
    "P_{ff} = W_ff + B_{ff}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above equation, F_{-1} \\times F is the total number of connection weights from neurons of the previous FC Layer the neurons of the current FC Layer. The total number of biases is the same as the number of neurons (F)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am thankful to this post.\n",
    "\n",
    "https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/?fbclid=IwAR3Wnc_pzQNcluv80serTW7xeIKeT-TvmHm0vFdhV4NjLY1_GjALZwHGf20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "pytorch4_python3",
   "language": "python",
   "name": "pytorch4_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
